{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cc65d0a",
   "metadata": {},
   "source": [
    "# Using Data Analysis Techniques and Machine Learning to Search for Dark Matter (IN PROGRESS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a976cdb9",
   "metadata": {},
   "source": [
    "## Introduction, etc. here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abf0c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #So we can store data in DataFrames (an object type that makes for easier analysis)\n",
    "import numpy as np #used for calculations\n",
    "import uproot3 #allows us to accesss the data within the files we are using\n",
    "import matplotlib.pyplot as plt #used for plotting graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0bde4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'C:\\\\Users\\\\Chris\\\\Desktop\\\\Internship\\\\Data\\\\mc_306109.dmV_Zll_MET40_DM1_MM800.exactly2lep.root'\n",
    "#notice this is in the .root format used for CERN data, so we need the uproot3 module to access it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b311ffd0",
   "metadata": {},
   "source": [
    "Data from: https://atlas-opendata.web.cern.ch/atlas-opendata/samples/2020/exactly2lep/MC/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a55616c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_open = uproot3.open(data_path)[\"mini\"] #open data file (whats mini?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e097e6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = file_open.keys()\n",
    "show = file_open.show()\n",
    "#these two are similar and show the labels of all the columns of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c41caff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {} #dictionary to hold all the data that we will be looking at\n",
    "\n",
    "\n",
    "relevant_data = ['runNumber','eventNumber','channelNumber','mcWeight','lep_n','lep_truthMatched','lep_trigMatched',\n",
    "                'lep_pt','lep_eta','lep_phi','lep_E','lep_z0','lep_charge','lep_type','lep_isTightID','lep_ptcone30',\n",
    "                 'lep_etcone20','lep_trackd0pvunbiased','lep_tracksigd0pvunbiased','met_et','lep_pt_syst','XSection',\n",
    "                 'SumWeights']\n",
    "# these are the headings of the columns of data that we will be looking at\n",
    "relevant_data_locations = [0,1,2,3,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,63,68,69]\n",
    "\n",
    "\n",
    "#the below lines read the data that we are going to use into the dictionary above\n",
    "counter = 0\n",
    "for i in relevant_data_locations:\n",
    "    data_dict[relevant_data[counter]] = file_open.array(keys[i]) \n",
    "    #creates a new key in the dictionary using the entries in relevant_data, and adds the corresponding data values by opening\n",
    "    #the right array of data (using the column number given in relevant_data_locations)\n",
    "    counter+=1\n",
    "    \n",
    "\n",
    "#data_dict\n",
    "#uncomment above to view the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6bb921",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_df = pd.DataFrame(data_dict) #makes a DataFrame from the constructed dictionary\n",
    "raw_data_df #view the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93ddd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in raw_data_df:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77abf4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lep1PT = []\n",
    "lep2PT = []\n",
    "for i in raw_data_df['lep_pt']:\n",
    "    lep1PT.append(i[0]*0.001)#decrease by a factor of 10^3 for TeV -> GeV\n",
    "    lep2PT.append(i[1]*0.001)\n",
    "    \n",
    "lep1PT_hist = plt.hist(lep1PT, bins=np.linspace(0,700,15), histtype='step', label='MC signal')\n",
    "plt.xlabel('Transverse Momentum of Lepton 1 (GeV)')\n",
    "plt.ylabel('Entries')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "lep2PT_hist = plt.hist(lep2PT, bins=np.linspace(0,700,15), histtype='step', color='orange', label='MC signal')\n",
    "plt.xlabel('Transverse Momentum of Lepton 2 (GeV)')\n",
    "plt.ylabel('Entries')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a23f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "lepMET_hist = plt.hist(raw_data_df['met_et']*0.001, bins=np.linspace(0,1000,21), histtype='step', label='MC Signal')\n",
    "plt.xlabel('Missing Transverse Energy (GeV)')\n",
    "plt.ylabel('Entries')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f27408",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
